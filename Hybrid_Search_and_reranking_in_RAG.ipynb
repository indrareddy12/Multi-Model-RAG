{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sunnysavita10/Indepth-GENAI/blob/main/Hybrid_Search_and_reranking_in_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHlE17nUjXnp"
   },
   "source": [
    "https://s4ds.org/\n",
    "\n",
    "https://www.icdmai.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qmp_SaX69q18",
    "outputId": "63596de4-d1d9-4d78-cf94-7586f314ec44"
   },
   "outputs": [],
   "source": [
    "!pip install weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQLSw3iJ_0RX",
    "outputId": "d628e74a-a8de-42d2-ed1a-522acb9c3f51"
   },
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4lpn398P__vR",
    "outputId": "2f217e89-f2ad-4b53-9968-dfa0d3c857ef"
   },
   "outputs": [],
   "source": [
    "!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSik_tYq-JRN"
   },
   "outputs": [],
   "source": [
    "import weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5rKS1Co-22r"
   },
   "outputs": [],
   "source": [
    "WEAVIATE_CLUSTER=\"https://hybridsearch-ewd5zpr1.weaviate.network\"\n",
    "WEAVIATE_API_KEY=\"\" # Replace with your Weaviate API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovLN44VY-6tU"
   },
   "outputs": [],
   "source": [
    "WEAVIATE_URL = WEAVIATE_CLUSTER\n",
    "WEAVIATE_API_KEY = WEAVIATE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z93YcxMF_iCN"
   },
   "outputs": [],
   "source": [
    "HF_TOKEN=\"\"  # Replace with your Hugging Face API token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUDJ74Ut_N-M"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFrBhzvM--rd"
   },
   "outputs": [],
   "source": [
    "client = weaviate.Client(\n",
    "    url=WEAVIATE_URL, auth_client_secret=weaviate.AuthApiKey(WEAVIATE_API_KEY),\n",
    "    additional_headers={\n",
    "         \"X-HuggingFace-Api-Key\": HF_TOKEN\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQJQDj68Cy4J",
    "outputId": "ccf1aad1-8ca1-4079-b284-2f60397d0cd1"
   },
   "outputs": [],
   "source": [
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ouOrLG2B9wj",
    "outputId": "3038912b-d5cb-4714-9803-6706392ca7cf"
   },
   "outputs": [],
   "source": [
    "client.schema.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zR5jAGHC3bS"
   },
   "outputs": [],
   "source": [
    "client.schema.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7l8nTgbRDCWt"
   },
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"classes\": [\n",
    "        {\n",
    "            \"class\": \"RAG\",\n",
    "            \"description\": \"Documents for RAG\",\n",
    "            \"vectorizer\": \"text2vec-huggingface\",\n",
    "            \"moduleConfig\": {\"text2vec-huggingface\": {\"model\": \"sentence-transformers/all-MiniLM-L6-v2\", \"type\": \"text\"}},\n",
    "            \"properties\": [\n",
    "                {\n",
    "                    \"dataType\": [\"text\"],\n",
    "                    \"description\": \"The content of the paragraph\",\n",
    "                    \"moduleConfig\": {\n",
    "                        \"text2vec-huggingface\": {\n",
    "                            \"skip\": False,\n",
    "                            \"vectorizePropertyName\": False,\n",
    "                        }\n",
    "                    },\n",
    "                    \"name\": \"content\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxlykBOsD4oW"
   },
   "outputs": [],
   "source": [
    "client.schema.create(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "boKhfW7xD8je",
    "outputId": "6dec38eb-ab67-428a-c5fa-79849de612f5"
   },
   "outputs": [],
   "source": [
    "client.schema.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fYFxszF_lTL"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers.weaviate_hybrid_search import WeaviateHybridSearchRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDD_FAKZ_sZK"
   },
   "outputs": [],
   "source": [
    "retriever = WeaviateHybridSearchRetriever(\n",
    "    alpha = 0.5,               # defaults to 0.5, which is equal weighting between keyword and semantic search\n",
    "    client = client,           # keyword arguments to pass to the Weaviate client\n",
    "    index_name = \"RAG\",  # The name of the index to use\n",
    "    text_key = \"content\",         # The name of the text key to use\n",
    "    attributes = [], # The attributes to return in the results\n",
    "    create_schema_if_missing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJLYAGHbE1Z5"
   },
   "outputs": [],
   "source": [
    "model_name = \"HuggingFaceH4/zephyr-7b-beta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1w6ml1DsEv-q",
    "outputId": "235602d0-14da-4ebb-fd21-fe314ed872c5"
   },
   "outputs": [],
   "source": [
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LtJsxhOmEzWX",
    "outputId": "ceb6003d-d09d-4e19-90fe-beb540912dc7"
   },
   "outputs": [],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7YcsnAveEiFy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import ( AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline, )\n",
    "from langchain import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yflg19-qEiJs"
   },
   "outputs": [],
   "source": [
    "# function for loading 4-bit quantized model\n",
    "def load_quantized_model(model_name: str):\n",
    "    \"\"\"\n",
    "    model_name: Name or path of the model to be loaded.\n",
    "    return: Loaded quantized model.\n",
    "    \"\"\"\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        quantization_config=bnb_config,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pfdzn1ukEiMd"
   },
   "outputs": [],
   "source": [
    "# initializing tokenizer\n",
    "def initialize_tokenizer(model_name: str):\n",
    "    \"\"\"\n",
    "    model_name: Name or path of the model for tokenizer initialization.\n",
    "    return: Initialized tokenizer.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, return_token_type_ids=False)\n",
    "    tokenizer.bos_token_id = 1  # Set beginning of sentence token id\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8UgT93sEiQK"
   },
   "outputs": [],
   "source": [
    "tokenizer = initialize_tokenizer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "1a3922c925d243fe825c2fdffc1ac440",
      "848a9e20a5ff46329ac18f0f168a5d52",
      "3c0f9911a51648cb8be3aaf49a806575",
      "3f634bcca28549c8b922c73c7b475d91",
      "25ddfbae30f74ca6b5baf5cc1d94bcb1",
      "de412a1000a94bea8707e1cdc8d805b7",
      "65283aca47324d5b917ba33f61e2f240",
      "7a27e7b7ea6045a7a855237fd2a009e8",
      "e85f3538253c482eb76e42e6341abb83",
      "791e2040d86848d6be8fbc486e8ab8b5",
      "201266a8824041118a32f623036eb633"
     ]
    },
    "id": "Csv9lG6cErbb",
    "outputId": "1984deee-8c48-49af-bd66-9ee1d3018221"
   },
   "outputs": [],
   "source": [
    "model = load_quantized_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "IplrZgxvEreX",
    "outputId": "82543b1a-a0bf-4693-e975-98fce166013b"
   },
   "outputs": [],
   "source": [
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    use_cache=True,\n",
    "    device_map=\"auto\",\n",
    "    #max_length=2048,\n",
    "    do_sample=True,\n",
    "    top_k=5,\n",
    "    max_new_tokens=100,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uo348jKvErhO"
   },
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uva-5Nkqpr8w"
   },
   "outputs": [],
   "source": [
    "doc_path=\"/content/Retrieval-Augmented-Generation-for-NLP.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTNRvdSNp9jC",
    "outputId": "68d151fe-ac47-4e64-9d56-7cabd3fb2c50"
   },
   "outputs": [],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ev8_SeQIp_4A",
    "outputId": "f4dc1edd-7f8d-4d60-da77-96284597c657"
   },
   "outputs": [],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3n-7-QWyp_8x"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhBRpl8dsHw6"
   },
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(doc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHegGUGssHzV"
   },
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpshkBhjvLlC",
    "outputId": "6fa66ef9-f60c-4e6a-ad16-0d1464f27246"
   },
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6DNTiAvgvNYC",
    "outputId": "3bc37592-d65b-473e-ae39-ec0dd2b79c40"
   },
   "outputs": [],
   "source": [
    "docs[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ux831sq2pq3C",
    "outputId": "3ee30aa3-f465-4d02-e4ea-4a2e07b6bc69"
   },
   "outputs": [],
   "source": [
    "retriever.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jRoDhLHjsy5f",
    "outputId": "9e1b9921-2fe7-4549-dfa0-b64fef8da144"
   },
   "outputs": [],
   "source": [
    "print(retriever.invoke(\"what is RAG token?\")[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WHdda33buBrS",
    "outputId": "843cffb4-caad-4033-97ce-e43c4035e3b3"
   },
   "outputs": [],
   "source": [
    "retriever.invoke(\n",
    "    \"what is RAG token?\",\n",
    "    score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vt5vaVuLEdY9"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkhbVjqiMJXJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "heu-l-l176Pp"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RrEl6Nm87_Vi"
   },
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"Use the given context to answer the question. \"\n",
    "    \"If you don't know the answer, say you don't know. \"\n",
    "    \"Use three sentence maximum and keep the answer concise. \"\n",
    "    \"Context: {context}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gg0TRf_Q72P6"
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GNPZSFun-4Ka"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you do not have the relevant information needed to provide a verified answer, don't try to make up an answer.\n",
    "When providing an answer, aim for clarity and precision. Position yourself as a knowledgeable authority on the topic, but also be mindful to explain the information in a manner that is accessible and comprehensible to those without a technical background.\n",
    "Always say \"Do you have any more questions pertaining to this instrument?\" at the end of the answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q3lt9jMW8hxK"
   },
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ppRiYOIa8b6y"
   },
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3t7fVtBaAOfq"
   },
   "outputs": [],
   "source": [
    "hybrid_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I0DfMLiJ6lbr",
    "outputId": "29e93eae-37ce-48b4-8c49-dd04a7195edc"
   },
   "outputs": [],
   "source": [
    "result1 = hybrid_chain.invoke(\"what is natural language processing?\")\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Flsjn21WMypT",
    "outputId": "3e4d6073-bfd3-4c31-b08c-d5fe399e8935"
   },
   "outputs": [],
   "source": [
    "print(result1['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhG3Krz99APy"
   },
   "outputs": [],
   "source": [
    "query=\"What is Abstractive Question Answering?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "hmmRp1O_ArC9",
    "outputId": "e56e99d7-4ddf-460a-e5a7-330b968d5cf6"
   },
   "outputs": [],
   "source": [
    "response = hybrid_chain.invoke({\"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZ-Id5sW-LLR"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1DvxugA-DIC"
   },
   "outputs": [],
   "source": [
    "# Set up the RAG chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} |\n",
    "    prompt |\n",
    "    llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OTU5Wycg-l9y"
   },
   "outputs": [],
   "source": [
    "query=\"what is RAG token?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykAekNO_-bkZ",
    "outputId": "140e6b43-ffac-43f3-c2bd-17959f6dea91"
   },
   "outputs": [],
   "source": [
    "response=rag_chain.invoke(\"what is RAG token?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqKKvHQ-_05x",
    "outputId": "a07f9be8-c605-4902-e957-7a005e296185"
   },
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWe11B_3H6Yc",
    "outputId": "08ac50fc-d407-4647-d7ac-ce0b786e5dd1"
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Y6DcD3Z5lZp",
    "outputId": "f792675c-237c-4e08-9f09-ed5229d4dad5"
   },
   "outputs": [],
   "source": [
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0A3hrUdwJ3pC"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VewE8gRKCla",
    "outputId": "48c1abc0-eb81-4bec-ada4-00c316b18120"
   },
   "outputs": [],
   "source": [
    "!pip install cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OE0vUax4J-Ij"
   },
   "outputs": [],
   "source": [
    "compressor = CohereRerank(cohere_api_key=\"\")  # Replace with your Cohere API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3Kmr4CIKG7n"
   },
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7m22qlCiUAb"
   },
   "outputs": [],
   "source": [
    "compressed_docs = compression_retriever.get_relevant_documents(user_query)\n",
    "# Print the relevant documents from using the embeddings and reranker\n",
    "print(compressed_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dKqM3XbKkE4"
   },
   "outputs": [],
   "source": [
    "hybrid_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=compression_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2N2k_RCmKAIL",
    "outputId": "466dc508-4180-48d4-f167-fd267628dd92"
   },
   "outputs": [],
   "source": [
    "response = hybrid_chain.invoke(\"What is Abstractive Question Answering?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVJxJg-bK2pg",
    "outputId": "9ee8590f-6350-4821-cb51-e497e4a020c0"
   },
   "outputs": [],
   "source": [
    "print(response.get(\"result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Wa3jBEgLwXB",
    "outputId": "d5e1a29a-5969-4ff2-d147-cdd49d2f7ed0"
   },
   "outputs": [],
   "source": [
    "print(response.get(\"result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcdaBC5gMCzh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
