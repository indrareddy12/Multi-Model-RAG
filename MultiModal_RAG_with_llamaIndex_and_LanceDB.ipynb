{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yn8jv85EiZn_"
   },
   "source": [
    "# **MultiModal RAG App for Video Processing With LlamaIndex and LanceDB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ZHVe_qkiYkg"
   },
   "source": [
    "### 1. llamaindex framework\n",
    "### 2. Lancedb Vector DataBase\n",
    "### 3. LLM MultiModAl GPT-4V or Google-gemini-pro-vision\n",
    "\n",
    "\n",
    "# **Steps Need to follow:**\n",
    "#### 1. Download video from YouTube, process and store it.\n",
    "\n",
    "#### 2. Build Multi-Modal index and vector store for both texts and images.\n",
    "\n",
    "#### 3. Retrieve relevant images and context, use both to augment the prompt.\n",
    "\n",
    "#### 4. Using GPT4V for reasoning the correlations between the input query and augmented data and generating final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sY9xSK0SihIG",
    "outputId": "22e8e2d4-aa21-4706-8660-76cb79a39caa"
   },
   "outputs": [],
   "source": [
    "%pip install llama-index-vector-stores-lancedb\n",
    "%pip install llama-index-multi-modal-llms-openai\n",
    "%pip install llama-index-embeddings-clip\n",
    "%pip install git+https://github.com/openai/CLIP.git\n",
    "!pip install llama-index-readers-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNZ4yrIMpa9S",
    "outputId": "cad849f2-6b95-4e56-b3c1-da66eb4a89bc"
   },
   "outputs": [],
   "source": [
    "%pip install llama_index\n",
    "%pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Y6xmSWjkppBJ",
    "outputId": "637cab2b-a090-47e5-b4e3-b88428ef65c2"
   },
   "outputs": [],
   "source": [
    "%pip install lancedb\n",
    "%pip install moviepy\n",
    "%pip install pytube\n",
    "%pip install pydub\n",
    "%pip install SpeechRecognition\n",
    "%pip install ffmpeg-python\n",
    "%pip install soundfile\n",
    "%pip install torch torchvision\n",
    "%pip install matplotlib scikit-image\n",
    "%pip install ftfy regex tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMlqUqibp0ji"
   },
   "source": [
    "ffmpeg-library enables you to use FFmpeg in Python to manipulate various media files for different purposes like building comprehensive multimedia applications, preprocessing media files.\n",
    "\n",
    "MoviePy is a Python library for video editing, enabling cutting, concatenations, title insertions, video compositing, and effects like animations or color grading.\n",
    "\n",
    "Pytube is a Python library used for downloading videos from YouTube. It supports downloading in various formats, resolutions, and also direct audio extraction.\n",
    "\n",
    "\n",
    "Pydub is a Python library for audio manipulation, enabling easy loading,\n",
    "editing, and exporting of audio files in various formats with minimal code.\n",
    "\n",
    "The SpeechRecognition library in Python allows you to convert spoken language into text using various engines and APIs, such as Google Speech Recognition, IBM Speech to Text, etc.\n",
    "\n",
    "\n",
    "SoundFile is a Python library for reading from and writing to audio files, supporting many formats through the libsndfile library, ideal for high-quality audio processing.\n",
    "\n",
    "FTFY (Fix Text For You) is a Python library that fixes broken Unicode text and mojibake (garbled text due to encoding issues), making text legible again.\n",
    "\n",
    "OpenAI Whisper is a robust, multilingual speech recognition model developed by OpenAI. It converts speech into text and supports various languages with high accuracy.\n",
    "\n",
    "pprint is a Python module that provides a capability to \"pretty-print\" complex data structures in a well-formatted and more readable way than the basic print function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igmrjXU6pwhu"
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from pathlib import Path\n",
    "import speech_recognition as sr\n",
    "from pytube import YouTube\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukX3ASTKqNDw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "OPENAI_API_TOKEN=userdata.get('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjxaH7FwqRGQ",
    "outputId": "ebaf140c-15b1-40db-e50f-69d441bb9aa1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dA6Lv4Hqp26"
   },
   "outputs": [],
   "source": [
    "video_url=\"https://youtu.be/3dhcmeOTZ_Q\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0TzZx3dbqrwq"
   },
   "outputs": [],
   "source": [
    "output_video_path = \"/content/video_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTx05t7bqcFv"
   },
   "outputs": [],
   "source": [
    "# from the video i am going to collect images,audio,text\n",
    "output_folder = \"/content/mixed_data/\"\n",
    "output_audio_path = \"/content/mixed_data/output_audio.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTzo50Y6qtmA"
   },
   "outputs": [],
   "source": [
    "!mkdir mixed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9SkpcGgq--g",
    "outputId": "4fc30558-b6f9-493b-8a5a-403d6f1e10ae"
   },
   "outputs": [],
   "source": [
    "filepath=output_video_path + \"input_vid.mp4\"\n",
    "print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwfB_9uhrB2F"
   },
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "def download_video(url,output_path):\n",
    "  yt = YouTube(url)\n",
    "  metadata = {\"Author\": yt.author, \"Title\": yt.title, \"Views\": yt.views}\n",
    "\n",
    "  yt.streams.get_highest_resolution().download(\n",
    "        output_path=output_path, filename=\"input_vid.mp4\"\n",
    "    )\n",
    "  return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lOX4wuBr8N6"
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "def video_to_images(video_path,output_folder):\n",
    "  clip=VideoFileClip(video_path)\n",
    "  clip.write_images_sequence(\n",
    "      os.path.join(output_folder,\"frame%04d.png\"),fps=0.2\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HPUIQSFsMkh"
   },
   "outputs": [],
   "source": [
    "def video_to_audio(video_path,output_audio_path):\n",
    "  clip=VideoFileClip(video_path)\n",
    "  audio=clip.audio\n",
    "  audio.write_audiofile(output_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_p39w53ZsRb5"
   },
   "outputs": [],
   "source": [
    "def audio_to_text(audio_path):\n",
    "  recognizer=sr.Recognizer()\n",
    "  audio=sr.AudioFile(audio_path)\n",
    "\n",
    "  with audio as source:\n",
    "    audio_data=recognizer.record(source)\n",
    "\n",
    "    try:\n",
    "\n",
    "      #recognize the speech\n",
    "      text = recognizer.recognize_whisper(audio_data)\n",
    "\n",
    "    except sr.UnknownValueError:\n",
    "      print(\"Speech recognition could not understand the audio.\")\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "RZnTqV_fslb2",
    "outputId": "e043f6f5-f3d3-4031-dae2-e260004fcb02"
   },
   "outputs": [],
   "source": [
    "video_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "KU1B6rEGsnVt",
    "outputId": "0bf343b3-b008-491f-c705-1d2d363476aa"
   },
   "outputs": [],
   "source": [
    "output_video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RblUwfbJshSJ"
   },
   "outputs": [],
   "source": [
    "metadata_vid = download_video(video_url, output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gwZJpGH8ssiM",
    "outputId": "3051ee60-9337-43ec-8698-9c4ccf6d9e6b"
   },
   "outputs": [],
   "source": [
    "metadata_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JbtVwXvgsqD8",
    "outputId": "5e51c2e6-cbea-4ad8-e76e-c444eb027bfc"
   },
   "outputs": [],
   "source": [
    "video_to_images(filepath,output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "XeIiBcBXs9fu",
    "outputId": "2dc35766-49b3-43e5-fc58-3128d316c97e"
   },
   "outputs": [],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "hhf-ckBDtAAe",
    "outputId": "4a97db0f-737a-440a-d555-e11f2135e538"
   },
   "outputs": [],
   "source": [
    "output_audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lhfIDRJLswtx",
    "outputId": "4d3e1a7e-c431-4590-ceb3-bbd4d680db13"
   },
   "outputs": [],
   "source": [
    "video_to_audio(filepath,output_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGIEgadAtCaq",
    "outputId": "49523efa-e6e1-4d56-9fcd-f25c4b377f10"
   },
   "outputs": [],
   "source": [
    "text_data=audio_to_text(output_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "TCEnFoCPtHq8",
    "outputId": "df721248-ec0e-4747-c6bc-34f254354d27"
   },
   "outputs": [],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgEEv89ptdHp",
    "outputId": "d9ceef12-1119-4595-d077-925034701218"
   },
   "outputs": [],
   "source": [
    "with open(output_folder + \"output_text.txt\", \"w\") as file:\n",
    "        file.write(text_data)\n",
    "print(\"Text data saved to file\")\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zse424_3tl9a",
    "outputId": "240eb1ac-2384-4ef4-e11b-3f31e8af11a5"
   },
   "outputs": [],
   "source": [
    "os.remove(output_audio_path)\n",
    "print(\"Audio file removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7KB6YBHJuCLt"
   },
   "outputs": [],
   "source": [
    "#process the video\n",
    "#image\n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vj4OUtZluIGG"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.indices import MultiModalVectorStoreIndex\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBBDEuXUutl5"
   },
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.lancedb import LanceDBVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUv_t8vMuxYK"
   },
   "outputs": [],
   "source": [
    "text_store=LanceDBVectorStore(uri=\"lancedb\",table_name=\"text_collection\")\n",
    "image_store=LanceDBVectorStore(uri=\"lancedb\",table_name=\"image_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ua0JXObmvRYN"
   },
   "outputs": [],
   "source": [
    "storage_context=StorageContext.from_defaults(vector_store=text_store,image_store=image_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "KCicDH2WvZvQ",
    "outputId": "8a22d126-c409-49fe-e68b-bde9f5edd5d0"
   },
   "outputs": [],
   "source": [
    "output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_B-UYzwtvXKq"
   },
   "outputs": [],
   "source": [
    "documents=SimpleDirectoryReader(output_folder).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbaU5Noqvdyk",
    "outputId": "6ea2eefc-b4fb-4eb6-f93b-17044a47b3fc"
   },
   "outputs": [],
   "source": [
    "index = MultiModalVectorStoreIndex.from_documents(documents,storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5vZLg_-vm2o"
   },
   "outputs": [],
   "source": [
    "retriever_engine=index.as_retriever(similarity_top_k=1, image_similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQ2viUQuvv8K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hTtlvjav2fw"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "from llama_index.core.schema import ImageNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3c5AB1KWv3yv"
   },
   "outputs": [],
   "source": [
    "def retrieve(retriever_engine, query_str):\n",
    "    retrieval_results = retriever_engine.retrieve(query_str)\n",
    "\n",
    "    retrieved_image = []\n",
    "    retrieved_text = []\n",
    "    for res_node in retrieval_results:\n",
    "        if isinstance(res_node.node, ImageNode):\n",
    "            retrieved_image.append(res_node.node.metadata[\"file_path\"])\n",
    "        else:\n",
    "            display_source_node(res_node, source_length=200)\n",
    "            retrieved_text.append(res_node.text)\n",
    "\n",
    "    return retrieved_image, retrieved_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZHW-10jwEla"
   },
   "outputs": [],
   "source": [
    "query=\"can you tell me what is linear regression? explain equation of the multiple linear regression?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "id": "byH2Aq95wK1B",
    "outputId": "048af396-0548-4ae2-ccb6-cfc00751a975"
   },
   "outputs": [],
   "source": [
    "img,text=retrieve(retriever_engine,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnCjdTmnwSVJ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_images(images_path):\n",
    "  images_shown = 0\n",
    "  plt.figure(figsize=(16, 9))\n",
    "  for img_path in images_path:\n",
    "        if os.path.isfile(img_path):\n",
    "            image = Image.open(img_path)\n",
    "\n",
    "            plt.subplot(2, 3, images_shown + 1)\n",
    "            plt.imshow(image)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "            images_shown += 1\n",
    "            if images_shown >= 5:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 532
    },
    "id": "ovyDQLk-wkcS",
    "outputId": "12fd36b6-c601-4f0b-e306-69d441fb3b31"
   },
   "outputs": [],
   "source": [
    "plot_images(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97bGd7wcyKTZ"
   },
   "outputs": [],
   "source": [
    "qa_tmpl_str=(\n",
    "    \"Based on the provided information, including relevant images and retrieved context from the video, \\\n",
    "    accurately and precisely answer the query without any additional prior knowledge.\\n\"\n",
    "\n",
    "    \"---------------------\\n\"\n",
    "    \"Context: {context_str}\\n\"\n",
    "    \"Metadata for video: {metadata_str} \\n\"\n",
    "\n",
    "    \"---------------------\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYVgHILHy5-X",
    "outputId": "81c6e61e-9acb-4942-87bb-06dea9d0f0aa"
   },
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-oEG3Q2zC0F"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "metadata_str=json.dumps(metadata_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrgFXHJIy_XU"
   },
   "outputs": [],
   "source": [
    "query_str=\"can you tell me what is linear regression and equation of linear regression?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VC4mg79yuMZ"
   },
   "outputs": [],
   "source": [
    "context_str = \"\".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNyOcu2fywnO"
   },
   "outputs": [],
   "source": [
    "image_documents = SimpleDirectoryReader( input_files=img).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUGGglIMwtHB"
   },
   "outputs": [],
   "source": [
    "from llama_index.multi_modal_llms.openai import OpenAIMultiModal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRrclz5dxlaj"
   },
   "outputs": [],
   "source": [
    "openai_mm_llm = OpenAIMultiModal(model=\"gpt-4-vision-preview\", api_key=OPENAI_API_TOKEN, max_new_tokens=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdzMuacuyWMR"
   },
   "outputs": [],
   "source": [
    "result=openai_mm_llm.complete(\n",
    "    prompt=qa_tmpl_str.format(\n",
    "        query_str=query_str,metadata_str=metadata_str\n",
    "    ),\n",
    "    image_documents=image_documents,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PGjzok8zKDS",
    "outputId": "039f8566-0095-4095-bd9c-1e261e2d359c"
   },
   "outputs": [],
   "source": [
    "pprint(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8Y8VyRbzYuB"
   },
   "outputs": [],
   "source": [
    "qa_tmpl_str=(\n",
    "    \"Based on the provided information, including relevant images and retrieved context from the video, \\\n",
    "    accurately and precisely answer the query without any additional prior knowledge.\\n\"\n",
    "\n",
    "    \"---------------------\\n\"\n",
    "    \"Metadata for video: {metadata_str} \\n\"\n",
    "\n",
    "    \"---------------------\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X24-KE-UznCS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
